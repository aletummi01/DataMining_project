Accuratezze nested CV: [0.90203584 0.90499391 0.89751175 0.90290586 0.90236686]
Media nested CV: 0.9020 Â± 0.0025
Test t (baseline = 0.5): t=327.8873, p=0.000000
Risultato: Differenza statisticamente significativa.
Addestramento e ottimizzazione iperparametri Random Forest (Grid Search)...
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] END max_depth=4, max_features=None, min_samples_leaf=3, min_samples_split=7, n_estimators=300; total time=  58.7s
[CV] END max_depth=4, max_features=None, min_samples_leaf=3, min_samples_split=7, n_estimators=300; total time=  57.9s
[CV] END max_depth=4, max_features=None, min_samples_leaf=3, min_samples_split=7, n_estimators=300; total time=  58.2s

Iperparametri ottimali: {'max_depth': 4, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 7, 'n_estimators': 300}
Modello salvato in random_forest_finale.pkl

--- Metriche TRAIN (Ottimistico) ---
  Accuracy : 0.9047
  Precision: 0.8937
  Recall   : 0.9082
  F1-score : 0.9009
  ROC-AUC  : 0.9049

Report di classificazione TRAIN (Ottimistico):
              precision    recall  f1-score   support

        Fake       0.92      0.90      0.91     15028
        True       0.89      0.91      0.90     13706

    accuracy                           0.90     28734
   macro avg       0.90      0.90      0.90     28734
weighted avg       0.90      0.90      0.90     28734


--- Metriche VALIDATION ---
  Accuracy : 0.9041
  Precision: 0.8973
  Recall   : 0.9022
  F1-score : 0.8998
  ROC-AUC  : 0.9040

Report di classificazione VALIDATION:
              precision    recall  f1-score   support

        Fake       0.91      0.91      0.91      3757
        True       0.90      0.90      0.90      3427

    accuracy                           0.90      7184
   macro avg       0.90      0.90      0.90      7184
weighted avg       0.90      0.90      0.90      7184


--- Metriche TEST (Finale) ---
  Accuracy : 0.8999
  Precision: 0.8924
  Recall   : 0.8985
  F1-score : 0.8954
  ROC-AUC  : 0.8998

Report di classificazione TEST (Finale):
              precision    recall  f1-score   support

        Fake       0.91      0.90      0.90      4696
        True       0.89      0.90      0.90      4284

    accuracy                           0.90      8980
   macro avg       0.90      0.90      0.90      8980
weighted avg       0.90      0.90      0.90      8980

Spiegazione LIME salvata in 'lime_explanation_rfr.html'